{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acccb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2bde42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create SparkSession. Then we read our dataset as a dataframe\n",
    "spark = SparkSession.builder.appName(\"mllib_siniflandirma\").getOrCreate()\n",
    "irisDataset = spark.read.csv(\"IRIS.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1dbdb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"species\" column does not come as an integer in the database,\n",
    "# That's why we convert the species column to a numeric label column using the StringIndexer.\n",
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"bitkiTuru\")\n",
    "trainingData = indexer.fit(trainingData).transform(trainingData)\n",
    "# indexed = indexer.fit(irisDataset).transform(irisDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "41cde131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We bring together the features required for classification\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "# We divide the training (70%) and test (30%) data\n",
    "(trainingData, testData) = indexed.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef37148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we train a classification model using, for example, DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a4d0458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the pipeline\n",
    "pipeline = Pipeline(stages=[assembler, indexer, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "752d3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the dataset\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71fe8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make predictions using the test dataset\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f947651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9512195121951219\n"
     ]
    }
   ],
   "source": [
    "# We get the accuracy value of the model we use\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
